from urllib import response
from openai import OpenAI  
from dotenv import load_dotenv
import os

load_dotenv()


OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Inicializar o cliente OpenAI corretamente
client = OpenAI(api_key=OPENAI_API_KEY)

modelo = os.getenv("model", "gpt-4.1-mini")  # Valor padr√£o se n√£o definido
temp = float(os.getenv("temperature", "0.7"))  # Converter para float com valor padr√£o
max_tokens = int(os.getenv("max_tokens", "150"))  # Converter para int com valor padr√£o
 
print(modelo)  
#print(client)
# Memoria
MAX_MEMORY = 6
memory = []

def limitar_memoria():
    global memory
    if len(memory) > MAX_MEMORY:
        memory = memory[-MAX_MEMORY:]
    
    
    
def pergunta(user_input: str):
    global memory

    # Adicionar a pergunta do usu√°rio √† mem√≥ria
    memory.append({"role": "user", "content": user_input})
    limitar_memoria()
    
    try:
        # print(f"[DEBUG] Enviando para API - Modelo: {modelo}, Temp: {temp}, Max Tokens: {max_tokens}")
        response = client.chat.completions.create(
            model=modelo,
            messages=[
                {"role": "system", "content": "Voc√™ √© um assistente de IA Python especializado em desenvolvimento de agentes inteligentes."},
                *memory
            ],
            temperature=temp,
            max_tokens=max_tokens
        )

        assistant_reply = response.choices[0].message.content
        print(f"[DEBUG] Resposta da IA: {assistant_reply}")

        # Captura de tokens
        if response.usage:
            tokens = response.usage
            print(f"[DEBUG] Tokens usados -> prompt: {tokens.prompt_tokens}, completion: {tokens.completion_tokens}, total: {tokens.total_tokens}")

        # Adicionar resposta do assistente √† mem√≥ria
        memory.append({"role": "assistant", "content": assistant_reply})
        limitar_memoria()

        return assistant_reply
    
    except Exception as e:
        error_msg = f"Erro ao conectar com a API: {str(e)}"
        print(f"[ERRO] {error_msg}")
        return error_msg


# Exemplo de uso interativo
if __name__ == "__main__":
    print("ü§ñ Assistente de IA (com mem√≥ria limitada a 6 intera√ß√µes)\n")
    print(f"[INFO] Modelo: {modelo}, Temperature: {temp}, Max Tokens: {max_tokens}\n")

    while True:
        user_message = input("Voc√™: ")
        if user_message.lower() in ["sair", "exit", "quit"]:
            print("Encerrando o assistente...")
            break

        reply = pergunta(user_message)
        print(f"\nAssistente: {reply}\n")
        
        print(memory)
        
        # Debug: mostrar o estado atual da mem√≥ria
        print(f"[DEBUG] Mem√≥ria atual ({len(memory)} itens)\n")
 #calcular custo dos tokens
 
#  PRECO_POR_1K_TOKENS = 0.01  # exemplo: 1 centavo por mil tokens
# custo = (tokens.total_tokens / 1000) * PRECO_POR_1K_TOKENS
# print(f"[INFO] Custo estimado desta requisi√ß√£o: ${custo:.4f}")
